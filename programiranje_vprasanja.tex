\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}

\begin{document}
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
 
        {\Large{\textbf{Vprašanja za ustni izpit pri Programiranju I}}}
    \end{center}
    \tableofcontents
\end{titlepage}
\section{Iztočnice za funkcijsko programiranje}
\subsection{Najpogostejši tipi v OCamlu}
okrajšave tipov
\begin{itemize}
    \item int
    \item float
    \item string
    \item unit
    \item char
    \item bool
\end{itemize}
Zelo pomembna je razlika med tipoma \textit{int} in \textit{float}. Pri \textit{intih} uporabljamo klasične operatorje, medtem, ko za \textit{floate} tem operatorjem dodamo piko na koncu. \\

tipi funkcije
$$
tip_{arg} \rightarrow tip_{rez}
$$
tip naborov \footnote{Prazen nabor je tipa unit().}
$$
tip_1 * tip_2 * \cdots * tip_n
$$
tip seznama
$$
tip_{el} \quad list
$$
OCaml je pri tipih v seznamu zelo dosleden. Hkrati so lahko v seznamu zgolj elementi istega tipa. \\

\noindent Vrednostim, ki imajo v tipih spremenljivke, pravimo \underline{parametrično polimorfne.} \textit{Using parametric polymorphism, a function or data type can be written generically so that it can handle values \underline{identically} without depending on their type.} \footnote{$\alpha$ tip}
\subsection{Primerjava med statičnimi in dinamičnimi tipi}
OCaml uporablja \underline{statične} tipe, Python pa \underline{dinamične}. \\

statični tipi:
\begin{itemize}
    \item compiler preveri, da so vsi tipi v funkciji pravi, preden poženemo program
    \item s tem pridobimo to, da funkcija vedno vrže isti tip ven, kar je zelo uporabno za kompozicije
\end{itemize}

dinamični tipi:
\begin{itemize}
    \item programski jezik preveri pravilnost funkcije šele, ko jo kličemo
\end{itemize}
OCamlovi tipi so bogatejši od Pythonovih, saj nam dajo več podatkov \footnote{Za sezname celih števil nam OCaml vrne tip \textit{int list}, medtem, ko Python vrne zgolj \textit{list}.}
\subsection{Repni klici in repna rekurzija}
Klic funkcije je \textit{repen}, če se izvede zadnji. Funkciji, kjer so vsi klici repni, pravimo \textit{repno rekurzivna funkcija}. 
Pri \textit{repno rekurzivnih funkcijah} spreminjamo samo akumulator, zato si računalniku
ni treba zapomniti celotnega procesa ampak zgolj vmesne vrednosti.\\

OCaml optimizira repne klice. \\

Python repnih klicev namenoma ne optimizira, da so sporočila
o napakah bolj poučna. Tega, da sklad ne raste, ne 
dosežemo tako, da optimiziramo repno rekurzijo, 
ampak da optimiziramo repne klice na splošno. Torej poljubna funkcija,
ki kliče drugo funkcijo, izgine iz kode. Razlog, zakaj ne 
želimo po privzetem načinu izvzeti repnih klicev je v tem,
da dobimo lep izpis o napakah. Če optimiziramo repne klice in
vmesne funkcije izginejo iz zgodbe, se lahko "\textit{izgubimo}". \footnote{PRI OBEH NAPIŠI PREDNOSTI IN SLABOSTI} \\ 

\subsection{Parametrični tipi in polimorfne funkcije}
\subsection{Funkcije višjega reda in anonimne funkcije}
Anonimne funkcije so funkcije, ki jih \textit{ne poimenujemo}. V OCamlu jih zapišemo kar kot \textit{fun x $\rightarrow$ fun(x)}. Uporabne so predvsem kadar jih uporabimo zgolj enkrat in na seznamu.
\begin{figure}[h!]
    \centering
    \includegraphics[width=100mm]{slike/anonimna_funkcija.png}
    \label{fig:anonimna funkcija}
\end{figure} \\

Funkcije nam ob dani spremenljivki vrnejo določene vrednosti. Če te vrednosti uporabimo naprej v drugi funkciji, govorimo o \textit{funkcijah višjega reda}. Torej funkcija višjega reda je vsaka 
funkcija, ki kot argument uporabi neko drugo funkcijo v določeni spremenljivki.
\begin{figure}[h!]
    \centering
    \includegraphics[width=100mm]{slike/funkcija_visjega_reda.png}
    \label{fig:funkcija visjega reda}
\end{figure} \\

Če funkciji, ki sprejme dva argumenta podamo samo en argument,
dobimo novo funkcijo. Če mi to funkcijo poimenujemo, jo lahko
(kasneje) uporabimo na drugem argumentu. \\

V OCamlu je navada, da pišemo \textit{fun x $\rightarrow$ fun(x)}. Operator $\rightarrow$ v tem zapisu je desno asociativen.
\subsection{Delno uporabljene funkcije in curryiranje}
Če imamo funkcijo, ki sprejme več argumentov, mi pa
ne podamo vseh, dobimo \textit{delno uporabljeno funkcijo}.
Dobimo torej novo funkcijo, ki ima sprejete že podane argumente,
na ostale pa čaka. Ko ji dodamo tudi ostale argumente, 
deluje identično, kot bi delovala, če ji vse argumente podamo
kar na začetku.\\

\noindent\underline{Curryirane funkcije} \footnote{Haskell Curry - po njem se imenuje tudi programski jezik Haskell.} \\

Imamo funkcijo dveh argumentov, ki torej sprejme prvi argument,
sprejme drugega in nekaj naredi. Če ji podamo samo prvi element,
dobimo novo funkcijo (ki čaka na drug argument). \\

To vidimo tudi kadar imamo funkcijo $f$, ki sprejme dva argumenta $x$ in $y$.
V OCamlu to napišemo kot $f x y$. Ta zapis je enak kot $(f x) y$,
torej $(f x)$ je funkcija, ki čaka še drugi argument $y$, ki je
v tem primeru že podan. \\

primer:
\begin{figure}[h!]
    \centering
    \includegraphics[width=100mm]{slike/curryiranje_tipi.png}
    \label{fig:curryiranje_tipi}
\end{figure}
\newpage
Tipa $A * B \rightarrow C$ in $A \rightarrow B \rightarrow C$ sta si izomorfna.
Prvi tip predstavlja \textit{običajno funkcijo dveh argumentov},
drugi pa \textit{Curryirano funkcijo dveh argumentov}. Izomorfizmu
med tema dvema funkcijama pravimo \textit{curryiranje}.
\begin{figure}[h!]
    \centering
    \includegraphics[width=100mm]{slike/curryiranje.png}
    \label{fig:curryiranje}
\end{figure}
\subsection{Vsote in induktivni tipi}
\subsection{Različice funkcije \textit{fold}}
Funkcije \textit{fold} so funkcije višjega reda. Gre za družino funkcij, ki "nabirajo" vrednosti elementov
po vrsti. Primer funkcije, ki sodi v družino \textit{fold}, je funkcija max. \\

\noindent Uporabimo v funkcijah, kjer sledimo vzorcu:
\begin{itemize}
    \item vzami seznam in začetno vrednost akumulatorja
    \item sprehodi se čez seznam
    \item za vsak element v seznamu \textit{naredi nekaj} 
    s trenutno vrednostjo akumulatorja in trenutnega elementa
    \item nadaljuj z iteracijo po seznamu
    \item ko prideš do konca seznama, vrni akumulator
\end{itemize}
Ta postopek lahko skrajšamo s funkcijo \textit{fold}, ki sprejme tri argumente. (\textit{funkcijo f, začetno vrednost akumulatorja} in \textit{seznam elementov}) \\

\noindent\texttt{fold\_right}
\begin{itemize}
    \item vrstni red združevanja elementov je desno $\rightarrow$ levo
    \item ni repno rekurzivna
\end{itemize}
\texttt{fold\_left}
\begin{itemize}
    \item vrstni red združevanja elementov je levo $\rightarrow$ desno
    \item repno rekurzivna
\end{itemize} 
Tipa funkcij sta različna.
\begin{figure}[h!]
    \centering
    \includegraphics[width=100mm]{slike/fold_funkciji.png}
    \label{fig: fold_funkciji}
\end{figure}
\subsection{Dokazovanje z indukcijo na seznamih in drevesih}
\underline{Indukcija na naravnih številih}
$$
P(0) \wedge (\forall m.P(m) \Rightarrow P(m^{+})) \Rightarrow \forall n.P(n)
$$
\underline{Indukcija na seznamih}
$$
P([]) \wedge (\forall x, xs. P(xs) \Rightarrow P(x :: xs)) \Rightarrow \forall ys.P(ys)
$$
ideja: \\

\noindent Vsak seznam je ali \textit{prazen} ali pa ima \textit{glavo in nek krajši seznam.} \footnote{Ignoriramo neskončne sezname.} 
Če imamo predikat $P$, ki velja na praznem seznamu in velja, 
da iz tega, ko $P$ velja na repu $xs$, $P$ velja tudi na
glavi in repu $x :: xs$, potem predikat $P$ velja na celem seznamu. \newline
Ne moremo reči, da $P$ velja za $x$, saj je $P$ predikat,
ki velja na seznamih, $x$ pa je zgolj element seznama, zato
je nesmiselno govoriti o $P(x)$. \newline
Indukcija na seznamih deluje, ker jo lahko prevedemo na
indukcijo na naravnih številih. Iz predikata $P$ na seznamih
moramo predelati predikat $Q$ na naravnih številih. To storimo tako,
da definiramo
$$
Q(n) := \forall ws. |ws| = n \Rightarrow P(ws).
$$
Z besedami to pomeni \textit{"$Q(n)$ bo veljalo, če za vse sezname dolžine $n$ velja $P(ws)$."}
V tem primeru je $Q(0)$ ekvivalentno $P([])$. To, da gremo iz
tega, da če velja za rep, velja tudi za glavo, je ravno korak
indukcije na naravnih številih. Mi predpostavimo, da velja za
sezname $\cdots$\footnote{DOPIŠI}. \\

\noindent\underline{Indukcija na drevesih}
$$
P(Empty) \wedge (\forall x, l, d. P(l) \wedge P(d) \Rightarrow P(Node(l, x, d))) \Rightarrow \forall t. P(t)
$$
Najprej pokažemo, da predikat velja za prazno drevo. V indukcijskem koraku
predpostavimo, da velja za \textit{levega in desnega otroka}.
Razlika od indukcije na dobro urejenih množicah je v tem,
da smo tam predpostavili, da velja za \textit{vse} manjše. Tu
predpostavimo, da velja samo za dve \textit{direktno manjši drevesi}.
Pomembno pri indukciji na drevesih je to, da imamo neko \textit{velikost}, nekaj, 
s čimer lahko indukcijo na drevesih prevedemo na indukcijo
na naravnih številih. Dober primer je \textit{globina}. \\
\newpage
\noindent\underline{Indukcija na poljubnem tipu}
\begin{figure}[h!]
    \centering
    \includegraphics[width=50mm]{slike/indukcija_na_ab.png}
    \label{fig:indukcija na ab}
\end{figure}
\begin{enumerate}
    \item pokažemo, da predikat $P$ velja na $A$
    \item pokažemo, da iz tega, da velja za \textit{"nek\_moj\_tip"}, velja tudi za $B$
\end{enumerate}
$$
P(A) \wedge \forall m. P(m) \Rightarrow P(B m) \Rightarrow \forall n. P(n)
$$
\underline{Indukcija za bool}
$$
P(A) \wedge P(B) \Rightarrow \forall b. P(b) \footnotemark
$$
\footnotetext{Predpostavki sta samo, da velja za $A$ in za $B$. Nimamo nobenih manjših problemov,
s katerimi bi prevedli na "navadno" indukcijo.}
\subsection{Signature in moduli}
Modularnost kode nam pomaga, da kodo razbijemo na manjše
enote, ki med seboj ustrezno sodelujejo. Osnovno modularnost nam
ponuja pisanje funkcij in tipi, dosežemo pa jo lahko tudi z
\textit{moduli}. \\

\noindent Modul je zbirka tipov in vrednosti. Vse definicije tipov in funkcij
lahko \textit{združimo} v zbirko in tej zbirki pravimo modul. 
Vsaka datoteka je že sama po sebi modul funkcij in tipov, ki
so napisane v tisti datoteki. Do tipov in funkcij modula dostopamo
tako, da napišemo \textit{modul.funkcija} oz. \textit{modul.tip}. \\

\noindent Razlika med datoteko funkcij in tipov in modulom je v tem, da lahko imamo
v eni datoteki več modulov. Vsebina modula je vse med \textit{struct} in \textit{end}.
Tip modula se imenuje \textit{signatura} in pove, kaj je v 
modulu shranjeno. \\

\noindent Funkcije lahko v modulu tudi skrivamo. Če signaturi
nekega modula priredimo novo signaturo, skrijemo vse funkcije,
ki niso definirane v novi signaturi. Funkcije lahko še vedno uporabljamo.
\newpage
\section{Iztočnice za podatkovne strukture in algoritme}
\subsection{Računska zahtevnost}
Računsko zahtevnost računamo s pomočjo velikega O.
$$
\exists M, x_0. \forall x > x_0. |f(x)| \leq M \cdot |g(x)|
$$
\begin{figure}[h!]
    \centering
    \includegraphics[width=100mm]{slike/racunska_zahtevnost_graf.png}
    \label{fig:graf racunske zahtevnosti}
\end{figure}

\noindent Ker z linearno funkcijo omejimo navzgor in 
ker je ničla linearne funkcije v $x = 0$, 
nas računska zahtevnost zanima zgolj za velike $x$. 
Časovna zahtevnost nam pove, koliko časa potrebuje program,
da nekaj izvede, prostorska zahtevnost pa koliko pomnilnika
pri tem porabi. \\

\noindent S $T(n)$ označimo čas, ki ga porabi funkcija 
za seznam dolžine $n$. Velja $T(0) = O(1)$, kar pomeni,
da za prazen seznam porabi konstanten čas. Čas, ki ga porabimo
za seznam dolžine $n + 1$ pa je $T(n + 1) = $. Seznam je potrebno
razpakirati (ločimo na glavo in rep), nato izvedemo funkcijo
na repu, ki je dolžine $n$. Pri tem porabimo torej $T(n)$ časa.
Na koncu damo še glavo nazaj, za kar porabimo $O(1)$ časa,
potem pa še staknemo. Pri stikanju gre za funkcijo na dveh seznamih.
Časovna zahtevnost je v odvisnoti od levega. \footnote{Dela rekurzivno
na levem.} \footnote{DODAJ ŠE SKICO IZRAČUNA ČASOVNE ZAHTEVNOSTI STIKANJA}
\newpage
\subsection{Iskalna drevesa in AVL drevesa}
Dvojiško\footnote{Ali je \textit{prazno}, ali ima pa \textit{koren in
levega in desnega otroka.}} drevo je \textit{iskalno}, če
\begin{itemize}
    \item so vsi elementi \textit{levega} otroka \textit{manjši} od korena
    \item so vsi elementi \textit{desnega} otroka \textit{večji} od korena
    \item sta oba otroka \textit{tudi iskalni drevesi}
\end{itemize}
V iskalna drevesa zelo lahko dodajamo in iščemo elemente. Pri odstranjevanju
se nam lahko zgodi, da pobrišemo koren nekega iskalnega poddrevesa.
V tem primeru koren nadomestimo z največjim manjšim elementom, torej
elementom, ki je skrajno desni na levi strani ali najmanjšim izmed največjih, torej s
skrajno levim na desni strani. \\ 

\noindent Očitno lahko v iskalna drevesa spravljamo zgolj elemente, 
ki jih lahko med seboj primerjamo. \\

\noindent Operacije v iskalnem drevesu imajo časovno zahtevnost $O(h)$. \footnote{\textit{h} pomeni height} Velja
le, če je drevo \textit{uravnoteženo}. Primeri uravnoteženih dreves 
so \textit{AVL drevesa}.\\

\noindent Iskalno drevo je AVL drevo, če
\begin{itemize}
    \item je razlika višin obeh otrok \textit{največ} $1$
    \item sta oba otroka \textit{tudi AVL drevesi}
\end{itemize}

\noindent Dodajanje in brisanje elementov AVL dreves jih lahko pokvari na enega
izmed dveh načinov. Lahko je globina levega poddrevesa za $2$ večja od
globine desnega ali obratno. Vsaka nadaljna neuravnoteženost
ima dve različici. Več kot dveh ne more imeti, saj AVL drevesa
tvorimo tako, da jih sproti urejamo, zaradi česar je razlika
globin obeh otrok ob vsakem trenutku največ $1$. To neuravnoteženost
lahko popravimo s pravo rotacijo. \footnote{RAZLOŽI, KDAJ UPORABIMO KAKŠNO ROTACIJO + 
POPRAVI MESTA SLIK}

\begin{figure}[h!]
    \centering
    \includegraphics[width=50mm]{slike/leva_rotacija.png}
    \label{fig:leva rotacija}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=75mm]{slike/desno_leva_rotacija.png}
    \label{fig: desno leva rotacija}
\end{figure}

\subsection{Spremenljive in nespremenljive podatkovne strukture}
\subsection{Predstavitev podatkov v pomnilniku}
V OCamlu so seznami implementirani z verižnimi seznami. To pomeni,
da vsak seznam sestavljata glava in rep.
\begin{figure}[h!]
    \centering
    \includegraphics[width=100mm]{slike/prikaz_veriznih_seznamov.png}
    \label{fig:prikaz_veriznih}
\end{figure}
\noindent V vsakem prostoru je napisan en podatek. Vidimo, da je seznam $s$
shranjen na mestu $19$. V pomnilniku je nato shranjeno tudi, da je to 
seznam, sestavljen iz glave in repa. Na naslednjih dveh mestih 
so podatki o glavi in repu. Glava oz. prvi element je torej $6$.
Na naslednjem mestu je spravljen podatek o repu, ampak tudi
repa ne moremo spraviti v zgolj en prostor, lahko si pa zapomnimo, kje 
je shranjen rep. Postopek se tako nadaljuje. \\

\noindent Prednost takega seznama je v tem, da lahko elemente
dodamo v seznam v konstantnem času, saj samo poiščemo prostor v pomnilniku
(potrebujemo dva kvadratka) za ta element in \textit{kazalec}, ki kaže na
rep seznama. Ko OCaml gleda pomnilnik ve, kdaj številka zgolj
kaže na mesto nadaljevanja seznama in kdaj predstavlja element v
seznamu. To mu omogočajo tipi. V Pythonu stvar deluje malo drugače. 
Seznam je  shranjen v enem kosu, kar pomeni, da če želimo
dodati nov element v seznam, moramo v pomnilniku poiskati dovolj
prostora za seznam dolžine $n - 1$ in element, ki ga želimo
dodati temu seznamu, nato pa cel seznam preslikamo na teh $n$ mest.
Časa porabimo linearno. \\

\noindent Primer pomnilnika za določeni seznam.
\begin{figure}[h!]
    \centering
    \includegraphics[width=100mm]{slike/pomnilnik_nov_seznam.png}
    \label{fig:pomnilnik nov seznam}
\end{figure}
\subsection{Razlika med verižnimi seznami in tabelami}
Verižni seznami so opisani že v zgornjem subsectionu.
\subsection{Metoda deli in vladaj}
Filozofija metode deli in vladaj je v tem, da problem razbijemo
na manjši problem. Izvedemo jo v treh korakih
\begin{itemize}
    \item nalogo razdelimo na manjše podnaloge
    \item podnaloge rekurzivno rešimo
    \item dobljene rešitve združimo v rešitev prvotne naloge
\end{itemize}
\underline{urejanje z zlivanjem} \\

\noindent Seznam damo na polovico in vsakega od njiju rekurzivno uredimo.
Dobimo dva urejena seznama, kjer vsak vsebuje polovico
prvotnega seznama. Nato gledamo glavi obeh urejenih seznamov in 
vsakič izberemo manjšega. Časovna zahtevnost tega algoritma je $n \cdot \log n$.
Vsakič razpolovimo in to razpolavljamo $\log n $ - krat. V vsakem
nivoju moramo razdeliti seznam na dva dela, kar je linearno. Ko
pridemo do seznamov dolžine $1$, jih uredimo v konstantnem času. Teh seznamov
je $n$, zato porabimo spet linearno časa. Dva seznama lahko zlijemo
skupaj $n$ - krat, torej je časovna zahtevnost $n$.
\begin{align*}
T(n) &= O(n) + 2 T(\frac{n}{2}) \\
&= O(n) + 2 (O(\frac{n}{2}) + 4 T(\frac{n}{4})) \\
&= \cdots \\
&= k O(n) + 2^{k} T(\frac{n}{2^{k}})
\end{align*}
Ta $k$ lahko povečujemo toliko časa, dokler ni $2^{k} \geq n$. 
To bo ravno pri logaritmu. Dobimo
\begin{align*}
&= \lceil \log_{2}n O(n) \rceil + 2^{\lceil \log_{2}n \rceil} O(1) \\
&= O(n \log n)
\end{align*}
\begin{itemize}
    \item povprečna časovna zahtevnost je $O(n \log n)$
    \item najslabša časovna zahtevnost je $O(n \log n)$
    \item prostorska zahtevnost je $O(n)$
\end{itemize}
\underline{hitro urejanje} \\

\noindent Ideja je, da se potrudimo, kako seznam razdelimo, 
vsak podseznam rekurzivno uredimo in ju neumno damo skupaj. Izberemo si \textit{pivot} točko in
vse elemente v seznamu uredimo glede na to točko, tako, da 
damo manjše v en seznam, večje pa od drugega. Pivot moramo izbrati
pametno. \footnote{Če je seznam urejen in izberemo prvi pivot, je ta algoritem precej
neučinkovit.} Najbolje je, da si izberemo tri pivot točke (začetek, 
sredina, konec) in za pivot točko izberemo sredinsko vrednost. 
Lahko tudi seznam razdelimo na dva dela (manjši, večji) 
in gledamo po elementih teh seznamov. Ko pridemo do 
elementa v levem delu, ki je večji od pivota in elementa v
desnem, ki je manjši ju zamenjamo. Nadaljujemo, 
dokler ne pridemo do konca. \footnote{POGLEJ SI ŠE DRUG NAČIN; TO JE
ZADNJIH 5'}
\begin{itemize}
    \item povprečna časovna zahtevnost je $O(n \log n)$
    \item najslabša časovna zahtevnost je $O(n^{2})$
    \item prostorska zahtevnost je $O(1)$
    \item v praksi hitreje, lokalna uporaba medpomnilnika
\end{itemize}

\noindent Obstajajo tudi algoritmi, ki ne delujejo s primerjanjem elementov. \\

\noindent\underline{urejanje s preštevanjem} \\

\noindent Uporabimo ga lahko, kadar vemo, katera števila so v seznamu. Zapeljemo
se čez seznam in za vsak element povečamo pravi števec. Ko pridemo
do konca, samo naredimo nov seznam, v katerem je toliko posameznih elementov,
kolikor je števec tega elementa. \\

\noindent \underline{radix sort} \\

\noindent Elemente uredimo po števkah od zadnje proti prvi. Časovna
zahtevnost je $n \cdot \text{število števk}$.
\subsection{Fisher - Yatesov algoritem}
\subsection{Algoritmi za urejanje}
\underline{urejanje z mehurčki} \footnote{intuicija - mehurčki v vodi plavajo navzgor, prav tako
gredo večji elementi proti vrhu seznama} \\

\noindent Vsakič pogledamo dva sosednja elementa. Če je prvi manjši od drugega,
ju pustimo pri miru, sicer ju zamenjamo. Tako se sprehajamo čez
seznam, dokler ne dobimo urejenega seznama. Časovna zahtevnost tega
algoritma je kvadratna. \footnote{$n$-krat gremo čez in vsakič imamo enega manj} \\

\noindent\underline{urejanje z izbiranjem} \\

\noindent Zapeljemo se čez seznam in poiščemo najmanjšega oz. največjega in
ga damo na začetek oz. na konec. Nato se ponovno zapeljemo čez
preostanek seznama. Časovna zahtevnost je kvadratna, saj je seznam
vedno manjši, ampak je manjši linearno. \\

\noindent \underline{urejanje z vstavljanjem} \\

\noindent Imamo neurejen seznam in ga urejamo enega po enega. 
Vsakič, ko dobimo nov element, pogledamo kam spada in ga vstavimo tja.
Bisekcije ne uporabljamo, ker sicer pravo mesto najdemo hitro (v logaritemskem času),
ampak moramo potem vse elemente prestaviti, za kar porabimo
linearno časa. Če iščemo enega po enega, s tem hkrati že premikamo. 
Pri bisekciji bi morali vse operacije ponoviti še enkrat. Časovna zahtevnost
je približno $\frac{n^2}{2}$. \\

\noindent Čeprav so to načeloma precej neoptimizirani algoritmi, niso nujno
neuporabni. Zelo lahko jih napišemo, na urejenih seznamih delujejo hitreje \footnote{Urejanje z
mehurčki bi šlo čez urejen seznam zgolj enkrat.}, tretja prednost pa je v
\textit{lokalnosti pomnilnika}. Če procesor deluje vedno na manjšem
kosu, recimo primerja dva sosednja elementa, je to precej hitreje, kot če bi
vsakega primerjal z vsakim. Na večjih seznamih zato navadno začnemo 
z zahtevnejšimi seznami, nato pa za majhne sezname uporabimo enega 
izmed zgornjih algoritmov.
\subsection{Časovna zahtevnost hitrega urejanja}
\subsection{Dinamično programiranje in memoizacija}
\end{document}